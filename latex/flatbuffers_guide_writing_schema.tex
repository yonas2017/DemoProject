\chapter{Writing a schema}
\hypertarget{flatbuffers_guide_writing_schema}{}\label{flatbuffers_guide_writing_schema}\index{Writing a schema@{Writing a schema}}
The syntax of the schema language (aka IDL, \href{https://en.wikipedia.org/wiki/Interface_description_language}{\texttt{ Interface Definition Language}}) should look quite familiar to users of any of the C family of languages, and also to users of other IDLs. Let\textquotesingle{}s look at an example first\+: \begin{DoxyVerb}// example IDL file

namespace MyGame;

attribute "priority";

enum Color : byte { Red = 1, Green, Blue }

union Any { Monster, Weapon, Pickup }

struct Vec3 {
  x:float;
  y:float;
  z:float;
}

table Monster {
  pos:Vec3;
  mana:short = 150;
  hp:short = 100;
  name:string;
  friendly:bool = false (deprecated, priority: 1);
  inventory:[ubyte];
  color:Color = Blue;
  test:Any;
}

root_type Monster;
\end{DoxyVerb}
 ({\ttfamily Weapon} \& {\ttfamily Pickup} not defined as part of this example).

\doxysubsection*{Tables}

Tables are the main way of defining objects in Flat\+Buffers, and consist of a name (here {\ttfamily Monster}) and a list of fields. Each field has a name, a type, and optionally a default value. If the default value is not specified in the schema, it will be {\ttfamily 0} for scalar types, or {\ttfamily null} for other types. Some languages support setting a scalar\textquotesingle{}s default to {\ttfamily null}. This makes the scalar optional.

Fields do not have to appear in the wire representation, and you can choose to omit fields when constructing an object. You have the flexibility to add fields without fear of bloating your data. This design is also Flat\+Buffer\textquotesingle{}s mechanism for forward and backwards compatibility. Note that\+:


\begin{DoxyItemize}
\item You can add new fields in the schema ONLY at the end of a table definition. Older data will still read correctly, and give you the default value when read. Older code will simply ignore the new field. If you want to have flexibility to use any order for fields in your schema, you can manually assign ids (much like Protocol Buffers), see the {\ttfamily id} attribute below.
\item You cannot delete fields you don\textquotesingle{}t use anymore from the schema, but you can simply stop writing them into your data for almost the same effect. Additionally you can mark them as {\ttfamily deprecated} as in the example above, which will prevent the generation of accessors in the generated C++, as a way to enforce the field not being used any more. (careful\+: this may break code!).
\item You may change field names and table names, if you\textquotesingle{}re ok with your code breaking until you\textquotesingle{}ve renamed them there too.
\end{DoxyItemize}

See "{}\+Schema evolution examples"{} below for more on this topic.

\doxysubsection*{Structs}

Similar to a table, only now none of the fields are optional (so no defaults either), and fields may not be added or be deprecated. Structs may only contain scalars or other structs. Use this for simple objects where you are very sure no changes will ever be made (as quite clear in the example {\ttfamily Vec3}). Structs use less memory than tables and are even faster to access (they are always stored in-\/line in their parent object, and use no virtual table).

\doxysubsection*{Types}

Built-\/in scalar types are


\begin{DoxyItemize}
\item 8 bit\+: {\ttfamily byte} ({\ttfamily int8}), {\ttfamily ubyte} ({\ttfamily uint8}), {\ttfamily bool}
\item 16 bit\+: {\ttfamily short} ({\ttfamily int16}), {\ttfamily ushort} ({\ttfamily uint16})
\item 32 bit\+: {\ttfamily int} ({\ttfamily int32}), {\ttfamily uint} ({\ttfamily uint32}), {\ttfamily float} ({\ttfamily float32})
\item 64 bit\+: {\ttfamily long} ({\ttfamily int64}), {\ttfamily ulong} ({\ttfamily uint64}), {\ttfamily double} ({\ttfamily float64})
\end{DoxyItemize}

The type names in parentheses are alias names such that for example {\ttfamily uint8} can be used in place of {\ttfamily ubyte}, and {\ttfamily int32} can be used in place of {\ttfamily int} without affecting code generation.

Built-\/in non-\/scalar types\+:


\begin{DoxyItemize}
\item Vector of any other type (denoted with {\ttfamily \mbox{[}type\mbox{]}}). Nesting vectors is not supported, instead you can wrap the inner vector in a table.
\item {\ttfamily string}, which may only hold UTF-\/8 or 7-\/bit ASCII. For other text encodings or general binary data use vectors ({\ttfamily \mbox{[}byte\mbox{]}} or {\ttfamily \mbox{[}ubyte\mbox{]}}) instead.
\item References to other tables or structs, enums or unions (see below).
\end{DoxyItemize}

You can\textquotesingle{}t change types of fields once they\textquotesingle{}re used, with the exception of same-\/size data where a {\ttfamily reinterpret\+\_\+cast} would give you a desirable result, e.\+g. you could change a {\ttfamily uint} to an {\ttfamily int} if no values in current data use the high bit yet.

\doxysubsection*{Arrays}

Arrays are a convenience short-\/hand for a fixed-\/length collection of elements. Arrays can be used to replace the following schema\+: \begin{DoxyVerb}struct Vec3 {
    x:float;
    y:float;
    z:float;
}
\end{DoxyVerb}
 with the following schema\+: \begin{DoxyVerb}struct Vec3 {
    v:[float:3];
}
\end{DoxyVerb}
 Both representations are binary equivalent.

Arrays are currently only supported in a {\ttfamily struct}.

\doxysubsection*{Default, Optional and Required Values}

There are three, mutually exclusive, reactions to the non-\/presence of a table\textquotesingle{}s field in the binary data\+:


\begin{DoxyEnumerate}
\item Default valued fields will return the default value (as defined in the schema).
\item Optional valued fields will return some form of {\ttfamily null} depending on the local language. (In a sense, {\ttfamily null} is the default value).
\item Required fields will cause an error. Flatbuffer verifiers would consider the whole buffer invalid. See the {\ttfamily required} tag below.
\end{DoxyEnumerate}

When writing a schema, values are a sequence of digits. Values may be optionally followed by a decimal point ({\ttfamily .}) and more digits, for float constants, or optionally prefixed by a {\ttfamily -\/}. Floats may also be in scientific notation; optionally ending with an {\ttfamily e} or {\ttfamily E}, followed by a {\ttfamily +} or {\ttfamily -\/} and more digits. Values can also be the keyword {\ttfamily null}.

Only scalar values can have defaults, non-\/scalar (string/vector/table) fields default to {\ttfamily null} when not present.

You generally do not want to change default values after they\textquotesingle{}re initially defined. Fields that have the default value are not actually stored in the serialized data (see also Gotchas below). Values explicitly written by code generated by the old schema old version, if they happen to be the default, will be read as a different value by code generated with the new schema. This is slightly less bad when converting an optional scalar into a default valued scalar since non-\/presence would not be overloaded with a previous default value. There are situations, however, where this may be desirable, especially if you can ensure a simultaneous rebuild of all code.

\doxysubsection*{Enums}

Define a sequence of named constants, each with a given value, or increasing by one from the previous one. The default first value is {\ttfamily 0}. As you can see in the enum declaration, you specify the underlying integral type of the enum with {\ttfamily \+:} (in this case {\ttfamily byte}), which then determines the type of any fields declared with this enum type.

Only integer types are allowed, i.\+e. {\ttfamily byte}, {\ttfamily ubyte}, {\ttfamily short} {\ttfamily ushort}, {\ttfamily int}, {\ttfamily uint}, {\ttfamily long} and {\ttfamily ulong}.

Typically, enum values should only ever be added, never removed (there is no deprecation for enums). This requires code to handle forwards compatibility itself, by handling unknown enum values.

\doxysubsection*{Unions}

Unions share a lot of properties with enums, but instead of new names for constants, you use names of tables. You can then declare a union field, which can hold a reference to any of those types, and additionally a field with the suffix {\ttfamily \+\_\+type} is generated that holds the corresponding enum value, allowing you to know which type to cast to at runtime.

It\textquotesingle{}s possible to give an alias name to a type union. This way a type can even be used to mean different things depending on the name used\+: \begin{DoxyVerb}table PointPosition { x:uint; y:uint; }
table MarkerPosition {}
union Position {
  Start:MarkerPosition,
  Point:PointPosition,
  Finish:MarkerPosition
}
\end{DoxyVerb}
 Unions contain a special {\ttfamily NONE} marker to denote that no value is stored so that name cannot be used as an alias.

Unions are a good way to be able to send multiple message types as a Flat\+Buffer. Note that because a union field is really two fields, it must always be part of a table, it cannot be the root of a Flat\+Buffer by itself.

If you have a need to distinguish between different Flat\+Buffers in a more open-\/ended way, for example for use as files, see the file identification feature below.

There is an experimental support only in C++ for a vector of unions (and types). In the example IDL file above, use \mbox{[}Any\mbox{]} to add a vector of Any to Monster table. There is also experimental support for other types besides tables in unions, in particular structs and strings. There\textquotesingle{}s no direct support for scalars in unions, but they can be wrapped in a struct at no space cost.

\doxysubsection*{Namespaces}

These will generate the corresponding namespace in C++ for all helper code, and packages in Java. You can use {\ttfamily .} to specify nested namespaces / packages.

\doxysubsection*{Includes}

You can include other schemas files in your current one, e.\+g.\+: \begin{DoxyVerb}include "mydefinitions.fbs";
\end{DoxyVerb}
 This makes it easier to refer to types defined elsewhere. {\ttfamily include} automatically ensures each file is parsed just once, even when referred to more than once.

When using the {\ttfamily flatc} compiler to generate code for schema definitions, only definitions in the current file will be generated, not those from the included files (those you still generate separately).

\doxysubsection*{Root type}

This declares what you consider to be the root table of the serialized data. This is particularly important for parsing JSON data, which doesn\textquotesingle{}t include object type information.

\doxysubsection*{File identification and extension}

Typically, a Flat\+Buffer binary buffer is not self-\/describing, i.\+e. it needs you to know its schema to parse it correctly. But if you want to use a Flat\+Buffer as a file format, it would be convenient to be able to have a "{}magic number"{} in there, like most file formats have, to be able to do a sanity check to see if you\textquotesingle{}re reading the kind of file you\textquotesingle{}re expecting.

Now, you can always prefix a Flat\+Buffer with your own file header, but Flat\+Buffers has a built-\/in way to add an identifier to a Flat\+Buffer that takes up minimal space, and keeps the buffer compatible with buffers that don\textquotesingle{}t have such an identifier.

You can specify in a schema, similar to {\ttfamily root\+\_\+type}, that you intend for this type of Flat\+Buffer to be used as a file format\+: \begin{DoxyVerb}file_identifier "MYFI";
\end{DoxyVerb}
 Identifiers must always be exactly 4 characters long. These 4 characters will end up as bytes at offsets 4-\/7 (inclusive) in the buffer.

For any schema that has such an identifier, {\ttfamily flatc} will automatically add the identifier to any binaries it generates (with {\ttfamily -\/b}), and generated calls like {\ttfamily Finish\+Monster\+Buffer} also add the identifier. If you have specified an identifier and wish to generate a buffer without one, you can always still do so by calling {\ttfamily Flat\+Buffer\+Builder\+::\+Finish} explicitly.

After loading a buffer, you can use a call like {\ttfamily Monster\+Buffer\+Has\+Identifier} to check if the identifier is present.

Note that this is best for open-\/ended uses such as files. If you simply wanted to send one of a set of possible messages over a network for example, you\textquotesingle{}d be better off with a union.

Additionally, by default {\ttfamily flatc} will output binary files as {\ttfamily .bin}. This declaration in the schema will change that to whatever you want\+: \begin{DoxyVerb}file_extension "ext";
\end{DoxyVerb}
 \doxysubsection*{RPC interface declarations}

You can declare RPC calls in a schema, that define a set of functions that take a Flat\+Buffer as an argument (the request) and return a Flat\+Buffer as the response (both of which must be table types)\+: \begin{DoxyVerb}rpc_service MonsterStorage {
  Store(Monster):StoreResponse;
  Retrieve(MonsterId):Monster;
}
\end{DoxyVerb}
 What code this produces and how it is used depends on language and RPC system used, there is preliminary support for GRPC through the {\ttfamily -\/-\/grpc} code generator, see {\ttfamily grpc/tests} for an example.

\doxysubsection*{Comments \& documentation}

May be written as in most C-\/based languages. Additionally, a triple comment ({\ttfamily ///}) on a line by itself signals that a comment is documentation for whatever is declared on the line after it (table/struct/field/enum/union/element), and the comment is output in the corresponding C++ code. Multiple such lines per item are allowed.

\doxysubsection*{Attributes}

Attributes may be attached to a declaration, behind a field/enum value, or after the name of a table/struct/enum/union. These may either have a value or not. Some attributes like {\ttfamily deprecated} are understood by the compiler; user defined ones need to be declared with the attribute declaration (like {\ttfamily priority} in the example above), and are available to query if you parse the schema at runtime. This is useful if you write your own code generators/editors etc., and you wish to add additional information specific to your tool (such as a help text).

Current understood attributes\+:


\begin{DoxyItemize}
\item {\ttfamily id\+: n} (on a table field)\+: manually set the field identifier to {\ttfamily n}. If you use this attribute, you must use it on ALL fields of this table, and the numbers must be a contiguous range from 0 onwards. Additionally, since a union type effectively adds two fields, its id must be that of the second field (the first field is the type field and not explicitly declared in the schema). For example, if the last field before the union field had id 6, the union field should have id 8, and the unions type field will implicitly be 7. IDs allow the fields to be placed in any order in the schema. When a new field is added to the schema it must use the next available ID.
\item {\ttfamily deprecated} (on a field)\+: do not generate accessors for this field anymore, code should stop using this data. Old data may still contain this field, but it won\textquotesingle{}t be accessible anymore by newer code. Note that if you deprecate a field that was previous required, old code may fail to validate new data (when using the optional verifier).
\item {\ttfamily required} (on a non-\/scalar table field)\+: this field must always be set. By default, fields do not need to be present in the binary. This is desirable, as it helps with forwards/backwards compatibility, and flexibility of data structures. By specifying this attribute, you make non-\/ presence in an error for both reader and writer. The reading code may access the field directly, without checking for null. If the constructing code does not initialize this field, they will get an assert, and also the verifier will fail on buffers that have missing required fields. Both adding and removing this attribute may be forwards/backwards incompatible as readers will be unable read old or new data, respectively, unless the data happens to always have the field set.
\item {\ttfamily force\+\_\+align\+: size} (on a struct)\+: force the alignment of this struct to be something higher than what it is naturally aligned to. Causes these structs to be aligned to that amount inside a buffer, IF that buffer is allocated with that alignment (which is not necessarily the case for buffers accessed directly inside a {\ttfamily \doxylink{classFlatBufferBuilder}{Flat\+Buffer\+Builder}}). Note\+: currently not guaranteed to have an effect when used with {\ttfamily -\/-\/object-\/api}, since that may allocate objects at alignments less than what you specify with {\ttfamily force\+\_\+align}.
\item {\ttfamily force\+\_\+align\+: size} (on a vector)\+: force the alignment of this vector to be something different than what the element size would normally dictate. Note\+: Now only work for generated C++ code.
\item {\ttfamily bit\+\_\+flags} (on an unsigned enum)\+: the values of this field indicate bits, meaning that any unsigned value N specified in the schema will end up representing 1\texorpdfstring{$<$}{<}\texorpdfstring{$<$}{<}N, or if you don\textquotesingle{}t specify values at all, you\textquotesingle{}ll get the sequence 1, 2, 4, 8, ...
\item {\ttfamily nested\+\_\+flatbuffer\+: "{}table\+\_\+name"{}} (on a field)\+: this indicates that the field (which must be a vector of ubyte) contains flatbuffer data, for which the root type is given by {\ttfamily table\+\_\+name}. The generated code will then produce a convenient accessor for the nested Flat\+Buffer.
\item {\ttfamily flexbuffer} (on a field)\+: this indicates that the field (which must be a vector of ubyte) contains flexbuffer data. The generated code will then produce a convenient accessor for the Flex\+Buffer root.
\item {\ttfamily key} (on a field)\+: this field is meant to be used as a key when sorting a vector of the type of table it sits in. Can be used for in-\/place binary search.
\item {\ttfamily hash} (on a field). This is an (un)signed 32/64 bit integer field, whose value during JSON parsing is allowed to be a string, which will then be stored as its hash. The value of attribute is the hashing algorithm to use, one of {\ttfamily fnv1\+\_\+32} {\ttfamily fnv1\+\_\+64} {\ttfamily fnv1a\+\_\+32} {\ttfamily fnv1a\+\_\+64}.
\item {\ttfamily original\+\_\+order} (on a table)\+: since elements in a table do not need to be stored in any particular order, they are often optimized for space by sorting them to size. This attribute stops that from happening. There should generally not be any reason to use this flag.
\item \textquotesingle{}native\+\_\+\texorpdfstring{$\ast$}{*}\textquotesingle{}. Several attributes have been added to support the \doxysectlink{flatbuffers_guide_use_cpp_flatbuffers_cpp_object_based_api}{C++ object}{1} Based API"{}.  All such attributes     are prefixed with the term "{}native\+\_\+"{}.   $<$h1$>$\+JSON Parsing$<$/h1$>$  \+The same parser that parses the schema declarations above is also able to parse JSON objects that conform to this schema. So, unlike other JSON parsers, this parser is strongly typed, and parses directly into a Flat\+Buffer (see the compiler documentation on how to do this from the command line, or the C++ documentation on how to do this at runtime).  \+Besides needing a schema, there are a few other changes to how it parses \+JSON\+:  -\/   It accepts field names with and without quotes, like many JSON parsers     already do. It outputs them without quotes as well, though can be made     to output them using the $<$tt$>$strict\+\_\+json$<$/tt$>$ flag. -\/   If a field has an enum type, the parser will recognize symbolic enum     values (with or without quotes) instead of numbers, e.\+g.     $<$tt$>$field\+: Enum\+Val$<$/tt$>$. If a field is of integral type, you can still use     symbolic names, but values need to be prefixed with their type and     need to be quoted, e.\+g. $<$tt$>$field\+: "{}Enum.\+Enum\+Val"{}$<$/tt$>$. For enums     representing flags, you may place multiple inside a string     separated by spaces to OR them, e.\+g.     $<$tt$>$field\+: "{}Enum\+Val1 Enum\+Val2"{}$<$/tt$>$ or $<$tt$>$field\+: "{}Enum.\+Enum\+Val1 Enum.\+Enum\+Val2"{}$<$/tt$>$. -\/   Similarly, for unions, these need to specified with two fields much like     you do when serializing from code. E.\+g. for a field $<$tt$>$foo$<$/tt$>$, you must     add a field $<$tt$>$foo\+\_\+type\+: Foo\+One$<$/tt$>$ right before the $<$tt$>$foo$<$/tt$>$ field, where     $<$tt$>$\+Foo\+One$<$/tt$>$ would be the table out of the union you want to use. -\/   A field that has the value $<$tt$>$null$<$/tt$>$ (e.\+g. $<$tt$>$field\+: null$<$/tt$>$) is intended to     have the default value for that field (thus has the same effect as if     that field wasn\textquotesingle{}t specified at all). -\/   It has some built in conversion functions, so you can write for example     $<$tt$>$rad(180)$<$/tt$>$ where ever you\textquotesingle{}d normally write $<$tt$>$3.\+14159$<$/tt$>$.     Currently supports the following functions\+: $<$tt$>$rad$<$/tt$>$, $<$tt$>$deg$<$/tt$>$, $<$tt$>$cos$<$/tt$>$, $<$tt$>$sin$<$/tt$>$,     $<$tt$>$tan$<$/tt$>$, $<$tt$>$acos$<$/tt$>$, $<$tt$>$asin$<$/tt$>$, $<$tt$>$atan$<$/tt$>$.  \+When parsing JSON, it recognizes the following escape codes in strings\+:  -\/   $<$tt$>$\textbackslash{}\textbackslash{}n$<$/tt$>$ -\/ linefeed. -\/   $<$tt$>$\textbackslash{}\textbackslash{}t$<$/tt$>$ -\/ tab. -\/   $<$tt$>$\textbackslash{}\textbackslash{}r$<$/tt$>$ -\/ carriage return. -\/   $<$tt$>$\textbackslash{}\textbackslash{}b$<$/tt$>$ -\/ backspace. -\/   $<$tt$>$\textbackslash{}\textbackslash{}f$<$/tt$>$ -\/ form feed. -\/   $<$tt$>$\textbackslash{}\textbackslash{}"{}$<$/tt$>$ -\/ double quote. -\/   $<$tt$>$\textbackslash{}\textbackslash{}\textbackslash{}\textbackslash{}$<$/tt$>$ -\/ backslash. -\/   $<$tt$>$\textbackslash{}\textbackslash{}/$<$/tt$>$ -\/ forward slash. -\/   $<$tt$>$\textbackslash{}\textbackslash{}u\+XXXX$<$/tt$>$ -\/ 16-\/bit unicode code point, converted to the equivalent UTF-\/8     representation. -\/   $<$tt$>$\textbackslash{}\textbackslash{}x\+XX$<$/tt$>$ -\/ 8-\/bit binary hexadecimal number XX. This is the only one that is      not in the JSON spec (see http\+://json.\+org/), but is needed to be able to      encode arbitrary binary in strings to text and back without losing      information (e.\+g. the byte 0x\+FF can\textquotesingle{}t be represented in standard JSON).  \+It also generates these escape codes back again when generating JSON from a binary representation.  \+When parsing numbers, the parser is more flexible than JSON. \+A format of numeric literals is more close to the C/\+C++. \+According to the @ref flatbuffers\+\_\+grammar "{}grammar"{}, it accepts the following numerical literals\+:  -\/   An integer literal can have any number of leading zero $<$tt$>$0$<$/tt$>$ digits.     Unlike C/\+C++, the parser ignores a leading zero, not interpreting it as the     beginning of the octal number.     The numbers $<$tt$>$\mbox{[}081, -\/00094\mbox{]}$<$/tt$>$ are equal to $<$tt$>$\mbox{[}81, -\/94\mbox{]}$<$/tt$>$  decimal integers. -\/   The parser accepts unsigned and signed hexadecimal integer numbers.     For example\+: $<$tt$>$\mbox{[}0x123, +0x45, -\/0x67\mbox{]}$<$/tt$>$ are equal to $<$tt$>$\mbox{[}291, 69, -\/103\mbox{]}$<$/tt$>$ decimals. -\/   The format of float-\/point numbers is fully compatible with C/\+C++ format.     If a modern C++ compiler is used the parser accepts hexadecimal and special     floating-\/point literals as well\+:     $<$tt$>$\mbox{[}-\/1.\+0, 2., .\+3e0, 3.\+e4, 0x21.\+34p-\/5, -\/inf, nan\mbox{]}$<$/tt$>$.      The following conventions for floating-\/point numbers are used\+:     -\/ The exponent suffix of hexadecimal floating-\/point number is mandatory.     -\/ Parsed $<$tt$>$\+Na\+N$<$/tt$>$ converted to unsigned IEEE-\/754 $<$tt$>$quiet-\/\+Na\+N$<$/tt$>$ value.      Extended floating-\/point support was tested with\+:     -\/ x64 Windows\+: $<$tt$>$\+MSVC2015$<$/tt$>$ and higher.     -\/ x64 Linux\+: $<$tt$>$\+LLVM 6.\+0$<$/tt$>$, $<$tt$>$\+GCC 4.\+9$<$/tt$>$ and higher.      For details, see @ref flatbuffers\+\_\+guide\+\_\+use\+\_\+cpp "{}Use in C++"{} section.  -\/   For compatibility with a JSON lint tool all numeric literals of scalar     fields can be wrapped to quoted string\+:     $<$tt$>$"{}1"{}, "{}2.\+0"{}, "{}0x48A"{}, "{}0x0\+C.\+0\+Ep-\/1"{}, "{}-\/inf"{}, "{}true"{}$<$/tt$>$.  $<$h1$>$\+Guidelines$<$/h1$>$  $<$h2$>$\+Efficiency$<$/h2$>$  \+Flat\+Buffers is all about efficiency, but to realize that efficiency you require an efficient schema. There are usually multiple choices on how to represent data that have vastly different size characteristics.  \+It is very common nowadays to represent any kind of data as dictionaries (as in e.\+g. JSON), because of its flexibility and extensibility. While it is possible to emulate this in Flat\+Buffers (as a vector of tables with key and value(s)), this is a bad match for a strongly typed system like Flat\+Buffers, leading to relatively large binaries. \+Flat\+Buffer tables are more flexible than classes/structs in most systems, since having a large number of fields only few of which are actually used is still efficient. You should thus try to organize your data as much as possible such that you can use tables where you might be tempted to use a dictionary.  \+Similarly, strings as values should only be used when they are truly open-\/ended. If you can, always use an enum instead.  \+Flat\+Buffers doesn\textquotesingle{}t have inheritance, so the way to represent a set of related data structures is a union. Unions do have a cost however, so an alternative to a union is to have a single table that has all the fields of all the data structures you are trying to represent, if they are relatively similar / share many fields. \+Again, this is efficient because non-\/present fields are cheap.  \+Flat\+Buffers supports the full range of integer sizes, so try to pick the smallest size needed, rather than defaulting to int/long.  \+Remember that you can share data (refer to the same string/table within a buffer), so factoring out repeating data into its own data structure may be worth it.  $<$h2$>$\+Style guide$<$/h2$>$  \+Identifiers in a schema are meant to translate to many different programming languages, so using the style of your "{}main"{} language is generally a bad idea.  \+For this reason, below is a suggested style guide to adhere to, to keep schemas consistent for interoperation regardless of the target language.  \+Where possible, the code generators for specific languages will generate identifiers that adhere to the language style, based on the schema identifiers.  -\/ Table, struct, enum and rpc names (types)\+: Upper\+Camel\+Case. -\/ Table and struct field names\+: snake\+\_\+case. This is translated to lower\+Camel\+Case   automatically for some languages, e.\+g. Java. -\/ Enum values\+: Upper\+Camel\+Case. -\/ namespaces\+: Upper\+Camel\+Case.  \+Formatting (this is less important, but still worth adhering to)\+:  -\/ Opening brace\+: on the same line as the start of the declaration. -\/ Spacing\+: Indent by 2 spaces. None around $<$tt$>$\+:$<$/tt$>$ for types, on both sides for $<$tt$>$=$<$/tt$>$.  \+For an example, see the schema at the top of this file.  $<$h1$>$\+Gotchas$<$/h1$>$  $<$h2$>$\+Schemas and version control$<$/h2$>$  \+Flat\+Buffers relies on new field declarations being added at the end, and earlier declarations to not be removed, but be marked deprecated when needed. We think this is an improvement over the manual number assignment that happens in \+Protocol Buffers (and which is still an option using the $<$tt$>$id$<$/tt$>$ attribute mentioned above).  \+One place where this is possibly problematic however is source control. If user \+A adds a field, generates new binary data with this new schema, then tries to commit both to source control after user B already committed a new field also, and just auto-\/merges the schema, the binary files are now invalid compared to the new schema.  \+The solution of course is that you should not be generating binary data before your schema changes have been committed, ensuring consistency with the rest of the world. If this is not practical for you, use explicit field ids, which should always generate a merge conflict if two people try to allocate the same id.  $<$h2$>$\+Schema evolution examples (tables)$<$/h2$>$  \+Some examples to clarify what happens as you change a schema\+:  \+If we have the following original schema\+: @iverbatim  table \{ a\+:int; b\+:int; \} @endiverbatim \+And we extend it\+: @iverbatim  table \{ a\+:int; b\+:int; c\+:int; \} @endiverbatim \+This is ok. Code compiled with the old schema reading data generated with the new one will simply ignore the presence of the new field. Code compiled with the new schema reading old data will get the default value for $<$tt$>$c$<$/tt$>$ (which is 0 in this case, since it is not specified). @iverbatim  table \{ a\+:int (deprecated); b\+:int; \} @endiverbatim \+This is also ok. Code compiled with the old schema reading newer data will now always get the default value for $<$tt$>$a$<$/tt$>$ since it is not present. Code compiled with the new schema now cannot read nor write $<$tt$>$a$<$/tt$>$ anymore (any existing code that tries to do so will result in compile errors), but can still read old data (they will ignore the field). @iverbatim  table \{ c\+:int; a\+:int; b\+:int; \} @endiverbatim \+This is NOT ok, as this makes the schemas incompatible. Old code reading newer data will interpret $<$tt$>$c$<$/tt$>$ as if it was $<$tt$>$a$<$/tt$>$, and new code reading old data accessing $<$tt$>$a$<$/tt$>$ will instead receive $<$tt$>$b$<$/tt$>$. @iverbatim  table \{ c\+:int (id\+: 2); a\+:int (id\+: 0); b\+:int (id\+: 1); \} @endiverbatim \+This is ok. If your intent was to order/group fields in a way that makes sense semantically, you can do so using explicit id assignment. Now we are compatible with the original schema, and the fields can be ordered in any way, as long as we keep the sequence of ids. @iverbatim  table \{ b\+:int; \} @endiverbatim \+NOT ok. We can only remove a field by deprecation, regardless of whether we use explicit ids or not. @iverbatim  table \{ a\+:uint; b\+:uint; \} @endiverbatim \+This is MAYBE ok, and only in the case where the type change is the same size, like here. If old data never contained any negative numbers, this will be safe to do. @iverbatim  table \{ a\+:int = 1; b\+:int = 2; \} @endiverbatim \+Generally NOT ok. Any older data written that had 0 values were not written to the buffer, and rely on the default value to be recreated. These will now have those values appear to $<$tt$>$1$<$/tt$>$ and $<$tt$>$2$<$/tt$>$ instead. There may be cases in which this is ok, but care must be taken. @iverbatim  table \{ aa\+:int; bb\+:int; \} @endiverbatim \+Occasionally ok. You\textquotesingle{}ve renamed fields, which will break all code (and JSON files!) that use this schema, but as long as the change is obvious, this is not incompatible with the actual binary buffers, since those only ever address fields by id/offset.  $<$h3$>$\+Schema evolution examples (unions)$<$/h3$>$  \+Suppose we have the following schema\+: @icode  union Foo \{ A, B \} @endicode  \+We can add another variant at the end. @icode  union Foo \{ A, B, another\+\_\+a\+: A \} @endicode  and this will be okay. Old code will not recognize $<$tt$>$another\+\_\+a$<$/tt$>$. \+However if we add $<$tt$>$another\+\_\+a$<$/tt$>$ anywhere but the end, e.\+g. @icode  union Foo \{ A, another\+\_\+a\+: A, B \} @endicode  this is not okay. When new code writes $<$tt$>$another\+\_\+a$<$/tt$>$, old code will misinterpret it as $<$tt$>$\+B$<$/tt$>$ (and vice versa). However you can explicitly set the union\textquotesingle{}s "{}discriminant"{} value like so\+: @icode  union Foo \{ A = 1, another\+\_\+a\+: A = 3, B = 2 \} @endicode  \+This is okay.  @icode  union Foo \{ original\+\_\+a\+: A = 1, another\+\_\+a\+: A = 3, B = 2 \} @endicode  \+Renaming fields will break code and any saved human readable representations, such as json files, but the binary buffers will be the same.       $<$br$>$  $<$h2$>$\+Testing whether a field is present in a table$<$/h2$>$  \+Most serialization formats (e.\+g. JSON or Protocol Buffers) make it very explicit in the format whether a field is present in an object or not, allowing you to use this as "{}extra"{} information.  \+Flat\+Buffers will not write fields that are equal to their default value, sometimes resulting in significant space savings. However, this also means we cannot disambiguate the meaning of non-\/presence as "{}written default value"{} or "{}not written at all"{}. This only applies to scalar fields since only they support default values. Unless otherwise specified, their default is 0.  \+If you care about the presence of scalars, most languages support "{}optional scalars."{} You can set $<$tt$>$null$<$/tt$>$ as the default value in the schema. $<$tt$>$null$<$/tt$>$ is a value that\textquotesingle{}s outside of all types, so we will always write if $<$tt$>$add\+\_\+field$<$/tt$>$ is called. The generated field accessor should use the local language\textquotesingle{}s canonical optional type.  \+Some $<$tt$>$\+Flat\+Buffer\+Builder$<$/tt$>$ implementations have an option called $<$tt$>$force\+\_\+defaults$<$/tt$>$ that circumvents this "{}not writing defaults"{} behavior you can then use $<$tt$>$\+Is\+Field\+Present$<$/tt$>$ to query presence. / \+Another option that works in all languages is to wrap a scalar field in a struct. This way it will return null if it is not present. This will be slightly less ergonomic but structs don\textquotesingle{}t take up any more space than the scalar they represent.    $<$h1$>$\+Writing your own code generator.$<$/h1$>$  \+See @ref intermediate\+\_\+representation "{}our intermediate representation"{}. 
\end{DoxyItemize}